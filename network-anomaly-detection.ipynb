{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Network Anomaly Detection","metadata":{"id":"U8EPxUaTTDvc"}},{"cell_type":"markdown","source":"## Contributors\n\n#### Amr Yasser 6772\n#### Elhussein Sabri 6716\n#### Marwan Khaled 7020\n","metadata":{"id":"5uWwgoaoTDvf"}},{"cell_type":"markdown","source":"## References \n[https://www.ecb.torontomu.ca/~bagheri/papers/cisda.pdf](Detailed Analysis of the KDD CUP 99 Data Set Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A. Ghorban)\nhttps://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html","metadata":{"id":"bc5lI45STDvg"}},{"cell_type":"markdown","source":"## Download Datset \n\nYou can Import data set from \n* [KDD CUP 1999 DATA](https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\nor Download it from kaggle","metadata":{"id":"AE2kEUD3TDvg"}},{"cell_type":"markdown","source":"### Imports","metadata":{"id":"8cMHbrvtTDvh"}},{"cell_type":"code","source":"import os\nfrom time import time\n\n# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport gzip\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import kneighbors_graph as knn\nfrom sklearn.metrics.pairwise import rbf_kernel as rbf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.metrics.cluster import contingency_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import entropy\nfrom tabulate import tabulate\nfrom sklearn.cluster import kmeans_plusplus","metadata":{"id":"pLElU1CbTDvh","execution":{"iopub.status.busy":"2023-04-17T00:42:02.442772Z","iopub.execute_input":"2023-04-17T00:42:02.443223Z","iopub.status.idle":"2023-04-17T00:42:03.998438Z","shell.execute_reply.started":"2023-04-17T00:42:02.443187Z","shell.execute_reply":"2023-04-17T00:42:03.996899Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## CoLab","metadata":{"id":"0A32uHiG5Ea3"}},{"cell_type":"code","source":"from google.colab import drive\n\n# mount drive\ndrive.mount('/content/drive')\n\npath_train = '/content/drive/MyDrive/Network Anomaly Detection/kddcup.data_10_percent.gz'\npath_test = '/content/drive/MyDrive/Network Anomaly Detection/corrected.gz'\npath_all = '/content/drive/MyDrive/Network Anomaly Detection/kddcup.data.gz'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6j-RReGTcSt","outputId":"5dd1e9d9-7121-464d-ce84-d555c009df55"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"}]},{"cell_type":"markdown","source":"## Kaggle","metadata":{"id":"RxurXjcJ5Hsf"}},{"cell_type":"code","source":"path_train = '/kaggle/input/kdd-cup-1999-data/kddcup.data_10_percent.gz'\npath_test = '/kaggle/input/kdd-cup-1999-data/corrected.gz'\npath_all = '/kaggle/input/kdd-cup-1999-data/kddcup.data.gz'","metadata":{"id":"w9-CuH3G5JCc","execution":{"iopub.status.busy":"2023-04-17T00:42:04.000454Z","iopub.execute_input":"2023-04-17T00:42:04.000928Z","iopub.status.idle":"2023-04-17T00:42:04.007718Z","shell.execute_reply.started":"2023-04-17T00:42:04.000877Z","shell.execute_reply":"2023-04-17T00:42:04.005529Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{"id":"dO32WtakTDvi"}},{"cell_type":"code","source":"def plot(x,y,title):\n    plt.figure(figsize=(8,6))\n    plt.bar(x,y)\n    plt.title(title)\n    plt.xlabel('Clusters')\n    plt.ylabel('Counts')\n    plt.show()\n\ndef analyze(model,ground_truth,pred,k):\n    print(f'K-Means at k = {model.n_clusters} after {model.execution_time}s:\\n')\n    labels , counts = np.unique(model.labels,return_counts=True)\n    plot(labels,counts,f'Clustering counts at k = {model.n_clusters} after {model.iterations} iterations')\n\n    labels, counts = np.unique(pred,return_counts = True)\n\n    precisions,recalls,fscores = accuracy_scores(ground_truth,pred)\n    data = []\n    dist = []\n    for i in range(k):\n      dist.append([i,counts[i]])\n      data.append([i,precisions[i],recalls[i],fscores[i]])\n\n    print(\"\\nClusters distribution\")\n    print(f'{tabulate(dist, headers=[\"Cluster\", \"Samples\"],tablefmt=\"psql\")}')\n    \n    print(\"\\nAccuracy measures\")\n    print(f'{tabulate(data, headers=[\"Cluster\", \"Precision\", \"Recall\", \"F-Score\"],tablefmt=\"psql\")}')\n    print(f'\\nF1-Score: {np.sum(fscores/k)}')\n    print(f'Clustering conditional entropy: {conditional_entropy(ground_truth,pred)}')\n\n\ndef cluster(k,init='++',mode='kmeans',sim='nn',nn=10,gamma=1.0):\n  if mode == 'kmeans':\n    model = KMeans(n_clusters = k,init = init).fit(train)\n    pred = model.predict(test)\n    analyze(model,ground_truth,pred,k)\n\n  if mode == 'spectral':\n    model = NCut(trainN,k, similarity=sim, nn=nn, gamma=gamma)\n    analyze(model,ground_truthN,model.labels,k)","metadata":{"id":"2AhR9dDMTDvi","execution":{"iopub.status.busy":"2023-04-17T00:42:04.010646Z","iopub.execute_input":"2023-04-17T00:42:04.013506Z","iopub.status.idle":"2023-04-17T00:42:04.030037Z","shell.execute_reply.started":"2023-04-17T00:42:04.013441Z","shell.execute_reply":"2023-04-17T00:42:04.028800Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# K-Means Implemenetation","metadata":{"id":"QRDkJXK7TDvj"}},{"cell_type":"code","source":"# Define the K-Means algorithm\nclass KMeans:\n    def __init__(self,n_clusters=3, init='++', max_iter=300,centroids=[]):\n        self.n_clusters = n_clusters\n        self.max_iter = max_iter\n        self.init = init\n        self.centroids = np.array(centroids)\n        self.iterations = 0\n    \n    def fit(self,train,random_state = None):\n        start = time()\n\n        # Initialize centroids randomly\n        if len(self.centroids) == 0:\n          if self.init == '++':\n            self.centroids, indices = kmeans_plusplus(train, n_clusters=self.n_clusters,random_state = random_state)\n          elif self.init == 'random':\n            self.centroids = np.array(train[np.random.choice(train.shape[0], self.n_clusters, replace=False)])   \n          else:\n            print('Init method not applicable')\n            return\n        \n        prev_centroids = np.zeros(self.centroids.shape)\n        self.labels = np.zeros(len(train),dtype='int8')\n\n        while np.not_equal(self.centroids, prev_centroids).any() and self.iterations < self.max_iter:\n            prev_centroids = self.centroids.copy()\n\n            # Assign each point to the closest centroid\n            distances = np.sqrt(((train - self.centroids[:, np.newaxis])**2).sum(axis=2))\n            self.labels = np.argmin(distances, axis=0)\n\n            # Update centroids\n            for i in range(self.n_clusters):\n                points = train[self.labels == i]\n                if len(points) > 0:\n                  self.centroids[i] = np.mean(points, axis=0)\n\n            # Catch any np.nans, resulting from a centroid having no points\n            for i, centroid in enumerate(self.centroids):\n                if np.isnan(centroid).any():  \n                    self.centroids[i] = prev_centroids[i]\n            \n            self.iterations += 1\n\n        end = time()\n        self.execution_time = end - start\n        \n        return self\n    \n    def predict(self,X):\n        predicted = []\n        distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))\n        predicted = np.argmin(distances, axis=0)\n        return np.array(predicted)","metadata":{"id":"HZruLFMpTDvj","execution":{"iopub.status.busy":"2023-04-17T00:42:07.493413Z","iopub.execute_input":"2023-04-17T00:42:07.493838Z","iopub.status.idle":"2023-04-17T00:42:07.511194Z","shell.execute_reply.started":"2023-04-17T00:42:07.493798Z","shell.execute_reply":"2023-04-17T00:42:07.510248Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Normalized Cuts Implementation","metadata":{"id":"qE9VbWcKTDvl"}},{"cell_type":"code","source":"# Define the Normalized Cuts algorithm\ndef NCut(train, k, nn=10, similarity= 'nn', gamma=1.0):\n    # Compute the similarity matrix\n    if similarity == 'nn':\n      sim = knn(train,nn,mode='connectivity').toarray()\n      A = sim + sim.T\n    elif similarity == 'rbf':\n      sim = rbf(train,train,gamma)\n      A = sim\n    else:\n      print('Similarity method not applicable')\n      return\n\n    # Compute the diagonal degree matrix\n    D = np.diag(np.sum(sim, axis=1)) \n\n    # Compute the Laplacian matrix\n    L = D - A\n\n    B = np.dot(np.linalg.inv(D),L)\n\n    eigenvalues,eigenvectors = np.linalg.eigh(B)\n\n    U = eigenvectors[:,:k]\n\n    Y = Normalizer().fit_transform(U)\n    \n    # Cluster the normalized eigenvectors using K-Means\n    model = KMeans(n_clusters = k).fit(Y)\n\n    return model","metadata":{"id":"kzvEyRCWTDvl","execution":{"iopub.status.busy":"2023-04-17T00:42:09.966074Z","iopub.execute_input":"2023-04-17T00:42:09.966463Z","iopub.status.idle":"2023-04-17T00:42:09.977894Z","shell.execute_reply.started":"2023-04-17T00:42:09.966429Z","shell.execute_reply":"2023-04-17T00:42:09.976585Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Implementation","metadata":{"id":"7_drYBHB5vPs"}},{"cell_type":"code","source":"# Conditional Entropy\ndef conditional_entropy(ground_truth,clusters):\n  con = contingency_matrix(ground_truth,clusters)\n\n  clusters_entropies = []\n\n  for cluster in con.T:\n    pT = cluster/np.sum(cluster)\n    clusters_entropies.append((np.sum(cluster)/len(ground_truth)) * entropy(pT,base=2))\n  \n  return np.sum(clusters_entropies)\n\n# Precision, Recall, and F1-Score\ndef accuracy_scores(ground_truth,clusters):\n  con = contingency_matrix(ground_truth,clusters)\n\n  labels , counts = np.unique(ground_truth,return_counts=True)\n  n_clusters = len(np.unique(clusters))\n  precision = []\n  recall = []\n  for cluster in con.T:\n    precision.append(cluster.max()/cluster.sum())\n    label = np.argmax(cluster)\n    recall.append(cluster[label]/counts[label])\n  \n  precision = np.array(precision)\n  recall = np.array(recall)\n  \n  return precision,recall,(2*precision*recall)/(precision+recall)","metadata":{"id":"6quIIak-5zGl","execution":{"iopub.status.busy":"2023-04-17T00:42:12.089877Z","iopub.execute_input":"2023-04-17T00:42:12.090309Z","iopub.status.idle":"2023-04-17T00:42:12.100346Z","shell.execute_reply.started":"2023-04-17T00:42:12.090273Z","shell.execute_reply":"2023-04-17T00:42:12.098835Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Data and formatting","metadata":{"id":"v0m9HBGNTDvm"}},{"cell_type":"code","source":"# Open and read the compressed data file using gzip\nwith gzip.open(path_train, 'rb') as f:\n    train_data = pd.read_csv(f, header=None)\n    \n\nwith gzip.open(path_test, 'rb') as f:\n    test_data = pd.read_csv(f, header=None)\n    \nwith gzip.open(path_all, 'rb') as f:\n    train_all_data = pd.read_csv(f, header=None)\n\n# Add column names to the DataFrame\ncols = [\n    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\",\n    \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\",\n    \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\",\n    \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n    \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n    \"dst_host_srv_rerror_rate\", \"label\"\n]\n\n\ntrain_data.columns  = cols\ntest_data.columns= cols\ntrain_all_data.columns = cols\n\n# removing the 2 samples with service = icmp as they do not match in train data\ntest_data = test_data[test_data.service != 'icmp']\n\nground_truth = LabelEncoder().fit_transform(test_data['label'])\n\n\ntrain_data.drop('label',axis=1,inplace=True)\ntest_data.drop('label',axis=1,inplace=True)\n\ntrain_all_y = train_all_data['label']\ntrain_all_data.drop('label',axis=1,inplace=True)\n\ntrainN,_,trainN_y,_ = train_test_split(train_all_data,train_all_y,train_size=0.0025, random_state = 42, stratify = train_all_y)\nground_truthN = LabelEncoder().fit_transform(trainN_y)\n","metadata":{"id":"LrKMpvvBTDvm","execution":{"iopub.status.busy":"2023-04-17T00:42:14.693724Z","iopub.execute_input":"2023-04-17T00:42:14.694135Z","iopub.status.idle":"2023-04-17T00:42:47.655943Z","shell.execute_reply.started":"2023-04-17T00:42:14.694098Z","shell.execute_reply":"2023-04-17T00:42:47.654804Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Pre Processing\n","metadata":{"id":"-ET15PUwTDvn"}},{"cell_type":"code","source":"# Convert categorical features to numerical features\ntrain_categorical_columns = train_data.select_dtypes(include=['object']).columns\n\nfor col in train_categorical_columns:\n    le = LabelEncoder().fit(train_data[col])\n\n    train_data[col] = le.transform(train_data[col])\n    test_data[col] = le.transform(test_data[col])\n    trainN[col] = LabelEncoder().fit_transform(trainN[col])\n\n\nscaler = MinMaxScaler().fit(train_data)\n\ntrain = scaler.transform(train_data)\ntest = scaler.transform(test_data)\n","metadata":{"id":"RV91lzk7TDvn","execution":{"iopub.status.busy":"2023-04-17T00:42:48.740636Z","iopub.execute_input":"2023-04-17T00:42:48.741646Z","iopub.status.idle":"2023-04-17T00:42:49.125585Z","shell.execute_reply.started":"2023-04-17T00:42:48.741581Z","shell.execute_reply":"2023-04-17T00:42:49.124519Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Clustering Using K-Means","metadata":{"id":"cq3xhqrITDvn"}},{"cell_type":"code","source":"# kmeans clustering with k = 7\ncluster(7)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T00:42:49.128182Z","iopub.execute_input":"2023-04-17T00:42:49.128504Z","iopub.status.idle":"2023-04-17T00:42:54.469338Z","shell.execute_reply.started":"2023-04-17T00:42:49.128472Z","shell.execute_reply":"2023-04-17T00:42:54.467552Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2110147625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# kmeans clustering with k = 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/332473929.py\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(k, init, mode, sim, nn, gamma)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'++'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/4138119734.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train, random_state)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Assign each point to the closest centroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# kmeans clustering with k = 15\ncluster(15)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pBqCOG0aaA3j","outputId":"8b5ec26d-5828-46d1-b9bb-4c4eb9959fb1","execution":{"iopub.status.busy":"2023-04-17T00:42:54.470175Z","iopub.status.idle":"2023-04-17T00:42:54.470617Z","shell.execute_reply.started":"2023-04-17T00:42:54.470394Z","shell.execute_reply":"2023-04-17T00:42:54.470417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kmeans clustering with k = 23\ncluster(23)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_32sun5Ybq0G","outputId":"bd2fc01d-84c0-4d27-98d8-9287b8930ff2","execution":{"iopub.status.busy":"2023-04-17T00:42:54.472261Z","iopub.status.idle":"2023-04-17T00:42:54.473066Z","shell.execute_reply.started":"2023-04-17T00:42:54.472682Z","shell.execute_reply":"2023-04-17T00:42:54.472739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kmeans clustering with k = 31\ncluster(31)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-JuCqNT7btCe","outputId":"acdd2e80-1490-4943-b673-7a4562bf04c7","execution":{"iopub.status.busy":"2023-04-17T00:42:54.475135Z","iopub.status.idle":"2023-04-17T00:42:54.475986Z","shell.execute_reply.started":"2023-04-17T00:42:54.475407Z","shell.execute_reply":"2023-04-17T00:42:54.475436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kmeans clustering with k = 45\ncluster(45)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tKJMjFflbvgi","outputId":"66938736-6013-4fa9-fb5c-5dbb0e986a3c","execution":{"iopub.status.busy":"2023-04-17T00:42:54.477817Z","iopub.status.idle":"2023-04-17T00:42:54.478517Z","shell.execute_reply.started":"2023-04-17T00:42:54.478188Z","shell.execute_reply":"2023-04-17T00:42:54.478226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering Using Normalized cut","metadata":{"id":"4qMR95q2dOW7"}},{"cell_type":"markdown","source":"## Using K-NN","metadata":{"id":"Mbvm9m_yzaAo"}},{"cell_type":"code","source":"cluster(23, mode='spectral', nn = 10)","metadata":{"id":"7wemkawz5RvN","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"141aaef2-770c-45a0-c939-c900e8a7b433","execution":{"iopub.status.busy":"2023-04-17T00:42:54.480154Z","iopub.status.idle":"2023-04-17T00:42:54.480747Z","shell.execute_reply.started":"2023-04-17T00:42:54.480415Z","shell.execute_reply":"2023-04-17T00:42:54.480446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using RBF Kernel","metadata":{"id":"csntiWmPzcyE"}},{"cell_type":"code","source":"cluster(23, mode='spectral', sim='rbf', gamma = 1.0)","metadata":{"id":"OHYxIYsYzf0V","execution":{"iopub.status.busy":"2023-04-17T00:42:54.482201Z","iopub.status.idle":"2023-04-17T00:42:54.482928Z","shell.execute_reply.started":"2023-04-17T00:42:54.482458Z","shell.execute_reply":"2023-04-17T00:42:54.482591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New Clustering Algorithm <Clustering Techinque>","metadata":{"id":"JOyDyIoiTDvo"}},{"cell_type":"code","source":"# DBSCAN Clustering\ndbscan = DBSCAN(eps=0.5, min_samples=5)\ndbscan.fit(train)\nlabels_db = dbscan.labels_\nsilhouette_db = silhouette_score(train, labels_db)\nprint(\"Silhouette Score for DBSCAN Clustering:\", silhouette_db)","metadata":{"id":"TQsu9wBsTDvo","trusted":true},"execution_count":null,"outputs":[]}]}